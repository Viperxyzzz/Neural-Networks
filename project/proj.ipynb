{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project\n",
    "#### Using ANN and CNN for handwritten digits and fashion detection\n",
    "\n",
    "In this project we plan to solve one of the most famous problems in machine learning - detection of handwritten digits.\n",
    "\n",
    "For this, we'll use two different approaches. \n",
    "\n",
    "The first one will be using ANN. ANN are a branch of machine learning models that are built on a collection of connected nodes called artifical neurons, which model the neurons in a biological brain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 12:52:28.412203: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:52:34.093569: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:52:34.099579: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:52:42.691639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os # responsible \n",
    "import cv2 # load images and process them\n",
    "import numpy as np # numpy arrays for further use with tensorflow\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import tensorflow as tf # machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset chosen was MNIST from TensorFlow datasets.\n",
    "\n",
    "MNIST is a large database of handwritten digits, that is commonly used for training image processing systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist= tf.keras.datasets.mnist\n",
    "data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)  = data\n",
    "\n",
    "#scaling it so all values are between 0 and 1\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # we have 60 000 entries with 28 by 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test # 9 different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnnNeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            tf.keras.layers.Flatten(input_shape=(28,28)), #flatten layer to flatten 28x28 pixels to 1x784 pixels\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu), # fully-connected layer, 128 units, relu activation function\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax) # output layer, 10 units because we have 10 digits, softmax activation function\n",
    "        ]\n",
    "        self.model = tf.keras.models.Sequential(self.layers)\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, x_train, y_train, epochs=3):\n",
    "        self.model.fit(x_train, y_train, epochs=epochs)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        val_loss, val_acc = self.model.evaluate(x_test, y_test)\n",
    "        return val_loss, val_acc\n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 12:52:51.707069: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.2649 - accuracy: 0.9206\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9671\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0734 - accuracy: 0.9769\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9682\n",
      "0.10389143973588943 0.9682000279426575\n",
      "INFO:tensorflow:Assets written to: ann_num_reader.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ann_num_reader.model/assets\n"
     ]
    }
   ],
   "source": [
    "ann = AnnNeuralNetwork()\n",
    "ann.train(x_train, y_train)\n",
    "val_loss, val_acc = ann.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)\n",
    "\n",
    "ann.save('ann_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "The number is probably a 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = ann.predict([x_test]) # make predictions\n",
    "print(\"The number is probably a\", np.argmax(predictions[12])) # print the first prediction\n",
    "plt.imshow(x_test[12], cmap=plt.cm.binary) # show the first image\n",
    "plt.show() # show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 12:53:19.224251: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.281469: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.300705: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.321599: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.322905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.333731: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.342604: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.377137: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.379060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.393805: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.395559: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.396490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.404352: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.436517: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.437402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.492334: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.498117: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.499493: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.499727: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.536405: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.537507: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:19.542335: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.683150: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 12:53:19.683892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 12:53:21.455223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:21.667304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:21.851004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:21.912261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:22.056006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:22.222863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:22.242368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:22.550491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 12:53:25.181482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:25.738674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:25.930999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:26.138895: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:26.284786: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:26.904073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:28.237693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-01-09 12:53:28.333379: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.968767 using {'batch_size': 10, 'epochs': 6}\n",
      "0.961283 (0.002923) with: {'batch_size': 10, 'epochs': 2}\n",
      "0.965733 (0.005038) with: {'batch_size': 10, 'epochs': 4}\n",
      "0.968767 (0.001759) with: {'batch_size': 10, 'epochs': 6}\n",
      "0.960783 (0.002073) with: {'batch_size': 20, 'epochs': 2}\n",
      "0.965383 (0.002187) with: {'batch_size': 20, 'epochs': 4}\n",
      "0.967950 (0.002496) with: {'batch_size': 20, 'epochs': 6}\n",
      "0.958717 (0.002713) with: {'batch_size': 40, 'epochs': 2}\n",
      "0.966283 (0.002461) with: {'batch_size': 40, 'epochs': 4}\n",
      "0.968667 (0.003152) with: {'batch_size': 40, 'epochs': 6}\n",
      "0.956583 (0.001847) with: {'batch_size': 60, 'epochs': 2}\n",
      "0.964017 (0.001474) with: {'batch_size': 60, 'epochs': 4}\n",
      "0.966700 (0.000041) with: {'batch_size': 60, 'epochs': 6}\n",
      "0.953767 (0.000726) with: {'batch_size': 80, 'epochs': 2}\n",
      "0.959667 (0.000878) with: {'batch_size': 80, 'epochs': 4}\n",
      "0.966083 (0.001496) with: {'batch_size': 80, 'epochs': 6}\n",
      "0.949717 (0.004540) with: {'batch_size': 100, 'epochs': 2}\n",
      "0.962033 (0.000487) with: {'batch_size': 100, 'epochs': 4}\n",
      "0.964683 (0.001181) with: {'batch_size': 100, 'epochs': 6}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Flatten(input_shape=(28,28)))\n",
    " model.add(Dense(128, activation='relu'))\n",
    " model.add(Dense(128, activation='relu'))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    " model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [2, 4, 6]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom scikeras.wrappers import KerasClassifier\\n\\ntuned_ann = AnnNeuralNetwork()\\nmodel = KerasClassifier(build_fn=tuned_ann, verbose=0)\\n\\nbatch_size = [10, 20, 40, 60, 80, 100]\\nepochs = [10, 50, 100]\\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\\ngrid_result = grid.fit(x_train, y_train)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "tuned_ann = AnnNeuralNetwork()\n",
    "model = KerasClassifier(build_fn=tuned_ann, verbose=0)\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is performing quite good on the digit dataset. Let us now use a more robust and hard dataset, the fashion_mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1769/1875 [===========================>..] - ETA: 0s - loss: 0.4898 - accuracy: 0.8210"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4844 - accuracy: 0.8227\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3553 - accuracy: 0.8685\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3217 - accuracy: 0.8784\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8708\n",
      "0.35695305466651917 0.8708000183105469\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "data = fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test)  = data\n",
    "\n",
    "#scaling it so all values are between 0 and 1\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "ann = AnnNeuralNetwork()\n",
    "ann.train(x_train, y_train)\n",
    "val_loss, val_acc = ann.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 14:43:45.181195: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:45.377998: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:45.381768: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:46.002179: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.035862: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.190179: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.191974: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:46.366095: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.367061: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:46.367624: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.556382: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.567875: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.568836: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:46.591453: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.746829: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.748512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:46.757889: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.920812: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:46.928500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:47.005660: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:47.007321: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:47.267187: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:47.459546: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 14:43:47.462688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 14:43:48.029643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:50.893745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:51.255859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:51.659116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:51.885663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:52.119480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:52.246495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-09 14:43:52.875408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 162 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n162 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/viper/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 760, in fit\n    self._fit(\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 915, in _fit\n    X, y = self._initialize(X, y)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 852, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 429, in _build_keras_model\n    model = final_build_fn(**build_params)\nTypeError: create_model() got an unexpected keyword argument 'activation'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model__activation\u001b[38;5;241m=\u001b[39mactivation, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m     33\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# summarize results\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (grid_result\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 162 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n162 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/viper/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 760, in fit\n    self._fit(\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 915, in _fit\n    X, y = self._initialize(X, y)\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 852, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/home/viper/.local/lib/python3.8/site-packages/scikeras/wrappers.py\", line 429, in _build_keras_model\n    model = final_build_fn(**build_params)\nTypeError: create_model() got an unexpected keyword argument 'activation'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [2, 3, 4]\n",
    "activation = ['softmax', 'relu', 'sigmoid']\n",
    "\n",
    "param_grid = dict(model__activation=activation, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
