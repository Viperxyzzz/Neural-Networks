{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project\n",
    "#### Using ANN and CNN to automatically detect handwritten digits\n",
    "\n",
    "In this project we plan to solve one of the most famous problems in machine learning - detection of handwritten digits.\n",
    "\n",
    "For this, we'll use two different approaches. \n",
    "\n",
    "The first one will be using ANN. ANN are a branch of machine learning models that are built on a collection of connected nodes called artifical neurons, which model the neurons in a biological brain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # responsible \n",
    "import cv2 # load images and process them\n",
    "import numpy as np # numpy arrays for further use with tensorflow\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import tensorflow as tf # machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset chosen was MNIST from TensorFlow datasets.\n",
    "\n",
    "MNIST is a large database of handwritten digits, that is commonly used for training image processing systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist= tf.keras.datasets.mnist\n",
    "data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)  = data\n",
    "\n",
    "#scaling it so all values are between 0 and 1\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnnNeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            tf.keras.layers.Flatten(input_shape=(28,28)), #flatten layer to flatten 28x28 pixels to 1x784 pixels\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu), # fully-connected layer, 128 units, relu activation function\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax) # output layer, 10 units because we have 10 digits, softmax activation function\n",
    "        ]\n",
    "        self.model = tf.keras.models.Sequential(self.layers)\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, x_train, y_train, epochs=3):\n",
    "        self.model.fit(x_train, y_train, epochs=epochs)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        val_loss, val_acc = self.model.evaluate(x_test, y_test)\n",
    "        return val_loss, val_acc\n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2629 - accuracy: 0.9233\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9669\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0727 - accuracy: 0.9767\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9707\n",
      "0.0959620550274849 0.9707000255584717\n",
      "INFO:tensorflow:Assets written to: ann_num_reader.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ann_num_reader.model/assets\n"
     ]
    }
   ],
   "source": [
    "ann = AnnNeuralNetwork()\n",
    "ann.train(x_train, y_train)\n",
    "val_loss, val_acc = ann.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)\n",
    "\n",
    "ann.save('ann_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = ann.predict([x_test]) # make predictions\n",
    "print(np.argmax(predictions[0])) # print the first prediction\n",
    "plt.imshow(x_test[0], cmap=plt.cm.binary) # show the first image\n",
    "plt.show() # show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
